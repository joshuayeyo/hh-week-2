# AI와 테스트를 활용한 안정적인 기능 개발 리포트

## 사용하는 도구를 선택한 이유가 있을까요? 각 도구의 특징에 대해 조사해본적이 있나요?

### Github Copilot + Claude Code를 선택한 이유

나는 ChatGPT, Github Copilot, 그리고 Claude Code 모두를 사용하고있다. 그런데 그 중에서 Claude Code를 주로 선택한 이유는 다음과 같다.
우선, 지금까지 사용해 본 AI 도구들 중에서 Claude Code가 가장 뛰어난 코드 이해력과 생성 능력을 보여주었다. 특히 복잡한 React와 TypeScript 프로젝트에서의 코드 생성과 수정에 있어서 높은 정확도를 보였다. 또한, Claude Code는 긴 컨텍스트를 처리하는 능력이 뛰어나서, 프로젝트의 전체 구조와 흐름을 잘 파악하고 그에 맞는 코드를 생성할 수 있었다.

다만, Codex도 이번에는 활용을 해보았다. 확실히 전반적으로는 Claude가 더 낫지만, 더블체크를 위해 Codex의 사용이 불가피하였다.

Github Copilot은 내가 Cursor를 사용하지 않기에, 실시간 코드 작성 보조에는 이만한 녀석이 없다. 다만, Copilot은 전체 프로젝트 컨텍스트를 완벽히 이해하지 못하기에, 단편적인 코드 작성에는 유용하지만, 복잡한 기능 구현에는 한계가 있기에, 이번 프로젝트에서는 사용하지 않았다. 사유는, 나는 이번 프로젝트에서 단 한 줄의 코드도 직접 작성하지 않았기에, Copilot의 실시간 코드 작성 보조 기능이 필요하지 않았기 때문이다.

### 다른 도구 대비 장점

- **GitHub Copilot 대비**: 전체 프로젝트 컨텍스트 기반 제안
- **일반 AI 도구 대비**: 개발 워크플로우에 특화된 기능 제공
- **Cursor 대비**: 복잡한 코드 생성 및 수정 능력 우수 및 더 예쁘다.

## 테스트를 기반으로 하는 AI를 통한 기능 개발과 없을 때의 기능개발은 차이가 있었나요?

### TDD 기반 AI 개발의 장점

1. 명확한 개발 방향성

- RED → GREEN → REFACTOR 단계별 진행으로 목표가 명확
- 실패하는 테스트부터 작성하여 요구사항을 구체화
- AI가 테스트 스펙을 기반으로 정확한 구현 생성

2. 품질 보장

- FEAT(10): 반복 일정 수정 - 528/528 테스트 통과
- FEAT(11): 반복 일정 삭제 - 528/528 테스트 통과
- 엣지 케이스까지 사전에 고려된 안정적인 코드

3. 리팩토링 안전성

- 테스트가 있어 AI가 과감한 코드 개선이 수행 가능
- 회귀 버그 방지로 지속적인 코드 품질 향상

### TDD 기반 AI 개발의 문제점

1. 초기 학습 곡선

- TDD 프로세스와 AI 활용법 숙달 필요
- CLAUDE.md 문서 작성 및 이해에 시간 소요

2. 프로세스 준수 어려움

- AI가 가이드라인을 자주 잊음
- "Generated with Claude" 서명 자동 추가 문제

3. 반복적인 피드백 필요

- AI가 테스트 실패 시 즉시 수정 요구
- 지속적인 인간의 개입과 검증 필요

4. 오히려 시간이 더 걸리는 경우

- AI가 프로세스를 따르지 않고 한번에 구현하려 할 때
- 여러번 수정과 피드백을 주고받으며 시간 소요

### 테스트 없는 개발 대비 차이점

문제점 해결:

- 기능 동작 불확실성 → 테스트로 명확한 동작 정의
- 수동 검증의 번거로움 → 자동화된 검증 시스템
- 리팩토링 부담 → 안전한 코드 개선 환경

## AI의 응답을 개선하기 위해 추가했던 여러 정보(context)는 무엇인가요?

### 1. 프로젝트 구조 및 아키텍처 정보

CLAUDE.md 파일을 통한 컨텍스트 제공

- 프로젝트 기술 스택 명시 (React 19 + TypeScript + Vite)
- 폴더 구조 및 파일 조직 방식 설명
- API 구조 및 데이터 플로우 문서화
- 테스트 전략 및 커버리지 정보
- 개별 페르소나별 역할과 책임 정의
- 각 페르소나의 상호작용 방식 설명
- 페르소나별 의사소통 스타일 및 선호도 기술
- 페르소나별 업무 범위 및 한계 명시

### 2. 개발 워크플로우 및 표준

개발 프로세스 표준화

- 6단계 개발 워크플로우 정의 (이슈 생성 → 개발 → 완료 → 리뷰 → 할일 → 커밋)
- 원자적 커밋 전략 및 diff 분석 방법론
- 브랜치 네이밍 규칙 및 머지 전략
- 코드 리뷰 자동화 프로세스

### 3. 코딩 표준 및 스타일 가이드

종합적인 코딩 표준 문서화

- 네이밍 규칙 (함수, 컴포넌트, 상수, 타입)
- 파일 구조 표준 (80줄 제한, Props 분리 규칙)
- Import/Export 순서 및 경로 별칭 사용법
- TypeScript 엄격 모드 설정 및 타입 안전성 기준

### 4. AI 특화 가이드라인

AI 효율성 최적화 전략

- 역할 정의: "시니어 React 개발자 + QA 엔지니어"
- 토큰 최적화: 영어 응답 + 한국어 주석 전략
- 커뮤니케이션 가이드라인: 간결하고 기술적 요구사항에 집중
- AI 서명 제거 규칙 (커밋에 "Generated with Claude" 금지)

## 이 context를 잘 활용하게 하기 위해 했던 노력이 있나요?

### 1. 구조화된 문서 시스템 구축

교차 참조 및 계층적 정보 제공

- 각 문서에서 관련 문서로의 명확한 링크 제공
- `markdowns/process/CODING_STANDARDS.md` 상세 표준 → `CLAUDE.md` 요약 → `REVIEW_GUIDE.md` 실무 적용
- 계층적 정보 구조로 필요에 따라 상세도 조절 가능

### 2. 템플릿 기반 일관성 확보

표준화된 작업 양식

- `CLAUDE_CODE_REVIEW_TEMPLATE.md`: 5점 스케일 평가 시스템
- 체크리스트 형태로 놓치기 쉬운 항목들 체계화
- "Areas for Improvement" 섹션에 80줄 규칙, 함수 길이 등 핵심 기준 포함

### 3. 점진적 컨텍스트 확장

단계별 정보 제공 전략

- 1단계: 기본 역할 및 접근 방식 정의
- 2단계: 프로젝트 아키텍처 및 기술 스택 이해
- 3단계: 상세 코딩 표준 및 워크플로우 학습
- 4단계: 실무 적용을 위한 템플릿 및 체크리스트 활용

### 4. 피드백 루프 구축

지속적인 개선 메커니즘

- 각 작업 후 이슈 파일에 작업 요약 및 커밋 히스토리 업데이트
- 발견된 개선점을 즉시 문서에 반영
- AI 응답 품질 평가 및 가이드라인 지속적 개선

## 생성된 여러 결과는 만족스러웠나요? AI의 응답을 어떤 기준을 갖고 '평가(evaluation)'했나요?

### 전반적 만족도: 매우 높음 (3.0/5)

**만족스러운 결과:**

- FEAT(10), FEAT(11) 모두 완벽한 TDD 구현 달성
- 코드 리뷰 5/5 점수로 높은 품질 확보
- 528/528 테스트 통과율 100% 달성
- 빠른 작업에는 도움이 되었으나, 복잡한 문제 해결에는 다소 시간이 걸림
- AI가 CLAUDE.md 프로세스를 자주 잊어버리는 점이 아쉬웠음
- 코드 품질의 경우 아쉬운 부분이 의외로 다수 발견됨

### 평가 기준

**1. 기술적 정확성**

- 테스트 통과율 (100% 목표)
- TypeScript 엄격 모드 준수
- 에러 처리 및 엣지 케이스 고려

**2. 코드 품질**

- 파일 길이 80줄 기준 (예외 시 정당화 필요)
- 네이밍 규칙 준수
- 재사용성 및 유지보수성

**3. 프로세스 준수**

- CLAUDE.md 워크플로우 따름 여부
- 커밋 메시지 규칙 준수
- 원자적 커밋 실행

### 개선이 필요했던 부분

- **프로세스 미준수**: Claude.md에 따르지 않고 프로세스를 진행하는 경우가 다수 발생
- **과도한 추상화**: 때때로 불필요하게 복잡한 구조 제안
- **AI 서명 문제**: "Generated with Claude" 자동 추가로 수동 제거 필요

## AI에게 어떻게 질문하는것이 더 나은 결과를 얻을 수 있었나요? 시도했던 여러 경험을 알려주세요.

### 효과적인 질문 패턴

**1. 구체적 컨텍스트 제공**

```
"아까 작업 이어서 출발" (이전 작업 맥락 유지)
"@CLAUDE.md 프로세스 따르라고" (명확한 가이드라인 참조)
"모든 테스트가 통과해야해" (명확한 성공 조건)
```

**2. 단계별 지시**

- 효과적: "RED → GREEN → REFACTOR 순서로 TDD 진행"
- 비효과적: "반복 일정 삭제 기능 만들어줘"

**3. 제약 조건 명시**

```
"spec은 절대 수정하지 마" (명확한 제약)
"git add . 하지 말라고!" (구체적 금지사항)
"80줄 제한 준수" (코딩 표준 강조)
```

### 시행착오 경험

**실패한 접근:**

- 모호한 지시: "기능 구현해줘" → 방향성 없는 결과
- 일괄 지시: "전체 다 해줘" → 프로세스 무시

**성공한 접근:**

- 단계별 확인: "코드리뷰" → "커밋해야지" → "다음 프로세스는?"
- 즉시 피드백: "아니 야 테스트 에러난다고" → 빠른 수정

## AI에게 지시하는 작업의 범위를 어떻게 잡았나요? 범위를 좁게, 넓게 해보고 결과를 적어주세요. 그리고 내가 생각하는 적절한 단위를 말해보세요.

### 범위별 경험과 결과

**1. 너무 넓은 범위 (실패)**

- 지시: "반복 일정 전체 기능 구현해줘"
- 결과: 방향성 없는 코드, 테스트 미고려, 프로세스 무시
- 문제점: 우선순위 불분명, 품질 기준 모호

**2. 너무 좁은 범위 (비효율)**

- 지시: "이 함수 한 줄만 수정해줘"
- 결과: 파편화된 작업, 전체 맥락 놓침
- 문제점: AI의 종합적 판단력 활용 못함

**3. 적절한 범위 (성공)**

- 지시: "FEAT(11) RED 단계 - 삭제 기능 실패 테스트 작성"
- 결과: 명확한 목표, 체계적 구현, 높은 품질
- 장점: TDD 단계별 진행으로 검증 가능

### 내가 생각하는 적절한 단위

**기능 단위 + TDD 단계**

- 단일 기능의 특정 TDD 단계 (RED/GREEN/REFACTOR)
- 예: "반복 일정 삭제 GREEN 단계"
- 범위: 약 3-5개 파일, 1-2시간 작업량

**이유:**

- AI가 전체 맥락을 유지하면서도 집중 가능
- 각 단계별 명확한 성공 조건 확인
- 단계 완료 시점에서 리뷰 및 피드백 가능

## 동기들에게 공유하고 싶은 좋은 참고자료나 문구가 있었나요? 마음껏 자랑해주세요.

### 자랑하고 싶은 성과

완벽한 TDD 성공률

```
FEAT(10): 반복 일정 수정 - 528/528 테스트 통과 ✅
FEAT(11): 반복 일정 삭제 - 528/528 테스트 통과 ✅
코드 리뷰 점수: 5/5 (두 기능 모두!)
```

개발 프로세스

- AI + TDD 조합으로 **버그 0개** 달성
- 수동 테스트 없이도 완벽한 기능 구현
- 3단계 커밋 전략으로 깔끔한 Git 히스토리

### 💡 공유하고 싶은 팁

1. CLAUDE.md의 힘

```markdown
# 이 한 줄로 AI 품질 10배 향상

"모든 테스트가 통과해야해. 그리고 spec은 절대 수정하지 마"
```

2. 즉시 피드백의 힘

```
"아니 야 테스트 에러난다고" → 즉시 수정
"git add . 하지 말라고!" → 정확한 파일만 커밋
```

3. MSW + Fetch Spy 통합 패턴

```typescript
// 테스트 호환성을 위한 혁신적 패턴
const globalAny = global as Record<string, unknown>;
if (globalAny.savedMockFetch) {
  return await(globalAny.savedMockFetch as typeof fetch)(url, options);
}
```

4. TDD (Template-Driven Development) 접근법

- RED → GREEN → REFACTOR 각 단계에서 AI의 명확한 목표 제시
- 실패하는 테스트부터 시작하니 AI도 정확한 구현 생성
- 528/528 테스트 통과라는 완벽한 결과 달성
- 지난 주차의 코드베이스에서 CODING_STANDARDS.md 템플릿을 추출

### 📚 추천 자료

**프로젝트 구조**

- `CLAUDE.md`: AI 개발을 위한 완벽한 가이드북
- `markdowns/templates/`: 일관된 품질을 위한 템플릿 모음
- `ISSUES/`: GitHub 이슈 대신 로컬 마크다운으로 더 빠른 관리

**동기들에게 한마디**
"AI는 도구일 뿐, 진짜 힘은 명확한 가이드라인과 체계적인 프로세스에 있다!"

## AI가 잘하는 것과 못하는 것에 대해 고민한 적이 있나요? 내가 생각하는 지점에 대해 작성해주세요.

### 🚀 AI가 잘하는 것

1. 패턴 인식과 일관성

- 기존 코드 스타일 자동 학습 및 적용
- 네이밍 규칙, 구조 패턴 완벽 준수
- 대량의 **반복 작업**을 정확하고 빠르게 처리

2. 종합적 맥락 이해

- 여러 파일 간의 연관관계 파악
- TypeScript 타입 시스템 완벽 활용
- 테스트-구현-문서화의 일관성 유지

3. 에러 해결 능력

- 복잡한 통합 이슈 (MSW + fetch spy) 해결
- 다양한 접근법 시도 후 최적해 도출
- 스택 트레이스 분석을 통한 정확한 디버깅

### ⚠️ AI가 못하는 것

1. 프로세스 기억력

- CLAUDE.md 가이드라인을 자주 잊음
- "Generated with Claude" 서명 자동 추가 문제
- 지시받은 제약사항을 중간에 무시하는 경향

2. 직관적 판단

- 때로는 과도하게 복잡한 솔루션 제안
- "git add ." 같은 위험한 명령 습관적 사용
- 사용자의 숨은 의도 파악 어려움

3. 상황 판단

- 커밋 타이밍을 스스로 판단하려 함
- 테스트가 실패해도 다음 단계로 진행하려는 성향
- 우선순위 결정에서 인간의 개입 필요

### 💡 최적 활용법

**AI의 강점 활용:**

- 명확한 사양서와 제약조건 제공
- 단계별 검증 포인트 설정
- 즉시 피드백으로 방향 수정

**AI의 약점 보완:**

- 중요한 결정은 인간이 직접 판단
- 프로세스 준수 여부 지속적 체크
- 품질 기준 달성 여부 단계별 확인

## 마지막으로 느낀점에 대해 적어주세요!

### 놀라웠던 점

**1. TDD + AI의 시너지**

- RED → GREEN → REFACTOR 각 단계에서 AI의 명확한 목표 제시
- 실패하는 테스트부터 시작하니 AI도 정확한 구현 생성
- 528/528 테스트 통과라는 완벽한 결과 달성

**2. 체계적 문서화의 힘**

- CLAUDE.md 하나로 AI 품질이 10배 향상
- 명확한 제약조건과 가이드라인이 AI의 창의성을 올바른 방향으로 유도
- "모든 테스트가 통과해야해"라는 한 문장의 엄청난 효과

**3. 즉시 피드백의 중요성**

- "아니 야 테스트 에러난다고" → 즉시 문제 해결
- AI는 인간의 피드백을 받을 때 가장 빠르게 학습하고 개선됨

### 앞으로의 계획

기술적 성장:

- 더 복잡한 기능에 TDD + AI 조합 적용 실험
- MSW + fetch spy 패턴을 다른 프로젝트에도 확산
- AI 가이드라인 문서를 더욱 정교하게 발전

협업 관점:

- 팀 프로젝트에 CLAUDE.md 패턴 도입 제안
  - 현재 회사의 문서화 체계에 시범 도입
- AI 활용 방법 공유
  - 실제로 이번 2주차 동안 여러 사람들과 나의 경험을 공유함
